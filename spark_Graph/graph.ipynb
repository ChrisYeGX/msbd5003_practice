{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sc.addPyFile(\"graphframes-0.7.0-spark2.4-s_2.11.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.sys.executable\n",
    "#sc.addPyFile(\"graphframes-0.7.0-spark2.4-s_2.11.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|  name|\n",
      "+-------+------+\n",
      "|  Fanny|Esther|\n",
      "|  David|Esther|\n",
      "|Charlie|Esther|\n",
      "+-------+------+\n",
      "\n",
      "+-------+------+\n",
      "|   name|  name|\n",
      "+-------+------+\n",
      "|  Fanny|Esther|\n",
      "|Charlie|Esther|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#g.find(\"(a)-[]->(b); (b)-[]->(d); (e)-[]->(f); (f)-[]->(a)\").filter(\" a.name = 'Alice'\").select(\"d.name\",'e.name').show()\n",
    "#g.find(\"(a)-[e]->(b)\").filter(\"b.name = 'Charlie' AND e.relationship = 'follow' \").select(\"a.name\").show()\n",
    "#g.vertices.join(g.inDegrees, 'id', 'left_outer').filter('inDegree >= 2').select(\"name\").show()\n",
    "from graphframes import *\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "\n",
    "# Vertics DataFrame\n",
    "\n",
    "v = spark.createDataFrame([\n",
    "\n",
    "  (\"a\", \"Alice\", 34),\n",
    "\n",
    "  (\"b\", \"Bob\", 36),\n",
    "\n",
    "  (\"c\", \"Charlie\", 37),\n",
    "\n",
    "  (\"d\", \"David\", 29),\n",
    "\n",
    "  (\"e\", \"Esther\", 32),\n",
    "\n",
    "  (\"f\", \"Fanny\", 38),\n",
    "\n",
    "  (\"g\", \"Gabby\", 60)\n",
    "\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "\n",
    "\n",
    "# Edges DataFrame\n",
    "\n",
    "e = spark.createDataFrame([\n",
    "\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "\n",
    "  (\"a\", \"e\", \"friend\"),\n",
    "\n",
    "  (\"g\", \"e\", \"follow\")\n",
    "\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "\n",
    "# Create a GraphFrame\n",
    "\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "\n",
    "#g.vertices.show()\n",
    "\n",
    "#g.edges.show()\n",
    "\n",
    "\n",
    "g.find(\"(a)-[]->(b); (b)-[]->(d); (e)-[]->(f); (f)-[]->(a)\").filter(\" a.name = 'Alice'\").select(\"d.name\",'e.name').show()\n",
    "g.find(\"(a)-[]->(b); (b)-[]->(d); !(d)-[]->(a);(e)-[]->(f); (f)-[]->(a);!(e)-[]->(a) \").filter(\" a.name = 'Alice'\").select(\"d.name\",'e.name').show()\n",
    "#g.find(\"(a)-[e]->(b)\").filter(\"b.name = 'Charlie' AND e.relationship = 'follow' \").select(\"a.name\").show()\n",
    "#g.vertices.join(g.inDegrees, 'id', 'left_outer').filter('inDegree >= 2').select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.vertices and g.edges are just DataFrames\n",
    "# You can use any DataFrame API on them\n",
    "\n",
    "g.edges.filter(\"src = 'a'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges.filter(\"src = 'a'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of followers of c.\n",
    "# This queries the edge DataFrame.\n",
    "print g.edges.filter(\"relationship = 'follow' and dst = 'c'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A GraphFrame has additional attributes\n",
    "\n",
    "g.outDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInDegrees = g.edges.groupBy('dst').count()\\\n",
    "               .withColumnRenamed('dst', 'id').withColumnRenamed('count', 'inDegree')\n",
    "myInDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInDegrees.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print g.inDegrees.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print g.inDegrees.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print g.vertices.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print g.vertices.storageLevel\n",
    "print g.edges.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A triplet view of the graph\n",
    "\n",
    "g.triplets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|           a|               b|\n",
      "+------------+----------------+\n",
      "|[b, Bob, 36]|[c, Charlie, 37]|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for pairs of vertices with edges in both directions between them.\n",
    "motifs = g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter('a.id < b.id')\n",
    "motifs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------------+\n",
      "|               a|               b|               c|\n",
      "+----------------+----------------+----------------+\n",
      "|  [a, Alice, 34]|  [g, Gabby, 60]|  [d, David, 29]|\n",
      "|  [a, Alice, 34]|[c, Charlie, 37]|  [d, David, 29]|\n",
      "|  [a, Alice, 34]|  [g, Gabby, 60]|[c, Charlie, 37]|\n",
      "|  [a, Alice, 34]|    [b, Bob, 36]|[c, Charlie, 37]|\n",
      "|  [a, Alice, 34]|[c, Charlie, 37]|  [g, Gabby, 60]|\n",
      "|[c, Charlie, 37]|  [d, David, 29]|  [g, Gabby, 60]|\n",
      "+----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find triangles\n",
    "\n",
    "triangles = g.find(\"(a)-[]->(b); (b)-[]->(c); (c)-[]->(a)\")\n",
    "triangles = triangles.filter(\"a.id < b.id AND a.id < c.id\")\n",
    "triangles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=sc.parallelize([(1,2),(1,3),(1,4),(2,3),(3,1)]).toDF([\"src\",\"dst\"])\n",
    "\n",
    "e1=e.withColumnRenamed('src', 'x').withColumnRenamed('dst','y')\n",
    "e2=e.withColumnRenamed('src', 'y1').withColumnRenamed('dst','z')\n",
    "e3=e.withColumnRenamed('src', 'z1').withColumnRenamed('dst','x1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'USING column `e1.y=e2.y1` cannot be resolved on the left side of the join. The left-side columns: [x, y];'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9413a62263dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# e2.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# e3.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'e1.y=e2.y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'left_outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"how should be basestring\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'USING column `e1.y=e2.y1` cannot be resolved on the left side of the join. The left-side columns: [x, y];'"
     ]
    }
   ],
   "source": [
    "# e1.show()\n",
    "# e2.show()\n",
    "# e3.show()\n",
    "e1.join(e2,'e1.y=e2.y1','left_outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|   name|               b|\n",
      "+-------+----------------+\n",
      "| Esther|  [d, David, 29]|\n",
      "|  Alice|    [b, Bob, 36]|\n",
      "|Charlie|  [d, David, 29]|\n",
      "|  Fanny|  [d, David, 29]|\n",
      "| Esther|  [a, Alice, 34]|\n",
      "|  Fanny|[c, Charlie, 37]|\n",
      "|  Fanny|    [b, Bob, 36]|\n",
      "|  David|  [a, Alice, 34]|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Negation\n",
    "oneway = g.find(\"(a)-[]->(b); !(b)-[]->(a)\")\n",
    "oneway.select(\"a.name\",'b').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find vertices without incoming edges. This is wrong:\n",
    "g.find('!()-[]->(a)').show()\n",
    "# Because negation is implemented as a subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still doesn't work:\n",
    "g.vertices.join(g.inDegrees, 'id').filter('inDegree=0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Why? Because inDegree is computed by a groupBy followed by a count\n",
    "g.inDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way:\n",
    "g.vertices.join(g.inDegrees, 'id', 'left_outer').filter('inDegree >= 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  a|\n",
      "|  b|\n",
      "|  c|\n",
      "|  d|\n",
      "|  e|\n",
      "|  f|\n",
      "|  g|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  f|\n",
      "|  e|\n",
      "|  d|\n",
      "|  c|\n",
      "|  b|\n",
      "|  a|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.vertices.select('id').show()\n",
    "g.inDegrees.select('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|  g|Gabby| 60|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Or use subtract:\n",
    "g.vertices.select('id').subtract(g.inDegrees.select('id')).join(g.vertices,'id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More meaningful queries can be expressed by applying filters.\n",
    "# Question: where is this filter applied?\n",
    "\n",
    "g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter(\"b.age > 36\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter(\"b.age > 36\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find chains of 4 vertices such that at least 2 of the 3 edges are \"friend\" relationships.\n",
    "# The when function is simvilar to the CASE WHEN in SQL\n",
    "\n",
    "chain4 = g.find(\"(a)-[e1]->(b); (b)-[e2]->(c); (c)-[e3]->(d)\").where('a!=d')\n",
    "\n",
    "friendTo1 = lambda e: when(e['relationship'] == 'friend', 1).otherwise(0)\n",
    "\n",
    "chain4.select('*',friendTo1(chain4['e1']).alias('f1'), \\\n",
    "                  friendTo1(chain4['e2']).alias('f2'), \\\n",
    "                  friendTo1(chain4['e3']).alias('f3')) \\\n",
    "      .where('f1 + f2 + f3 >= 2').select('a', 'b', 'c', 'd').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select subgraph of users older than 30, and edges of type \"friend\"\n",
    "v2 = g.vertices.filter(\"age > 30\")\n",
    "e2 = g.edges.filter(\"relationship = 'friend'\")\n",
    "g2 = GraphFrame(v2, e2)\n",
    "g2.vertices.show()\n",
    "g2.edges.show()\n",
    "\n",
    "# GraphFrames does not check if a vertex is isolated (which is OK)\n",
    "# or if an edge connects two existing vertices (which could cause bugs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2.inDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping edges that connect existing vertices\n",
    "e3 = e2.join(v2, e2['src'] == v2['id'], 'left_semi') \\\n",
    "       .join(v2, e2['dst'] == v2['id'], 'left_semi') \n",
    "g3 = GraphFrame(v2, e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subgraph based on edges of type \"follow\"\n",
    "# pointing from an older user to an younger user.\n",
    "e4 = g.find(\"(a)-[e]->(b)\")\\\n",
    "        .filter(\"e.relationship = 'follow'\")\\\n",
    "        .filter(\"a.age > b.age\") \\\n",
    "        .select(\"e.*\")\n",
    "e4.show()\n",
    "\n",
    "# Only keeping vertices that appear in the edges\n",
    "v4 = g.vertices.join(e4, g.vertices['id'] == e4['src'], 'leftsemi') \\\n",
    "      .union(g.vertices.join(e4, g.vertices['id'] == e4['dst'], 'leftsemi')) \\\n",
    "      .distinct()\n",
    "    \n",
    "# Construct the subgraph\n",
    "g4 = GraphFrame(v4, e4)\n",
    "g4.vertices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g4.triplets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting vertex is 'a'\n",
    "layers = [g.vertices.select('id').where(\"id = 'a'\")]\n",
    "visited =  layers[0]\n",
    "\n",
    "while layers[-1].count() > 0:\n",
    "    # From the current layer, get all the one-hop neighbors\n",
    "    d1 = layers[-1].join(g.edges, layers[-1]['id'] == g.edges['src'])\n",
    "    # Rename the column as 'id', and remove visited verices and duplicates\n",
    "    d2 = d1.select(d1['dst'].alias('id')) \\\n",
    "           .subtract(visited).distinct()\n",
    "    layers += [d2]\n",
    "    visited = visited.union(layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[2].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[3].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphFrames provides own BFS:\n",
    "\n",
    "paths = g.bfs(\"id = 'a'\", \"age > 36\")\n",
    "paths.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 denotes end of list\n",
    "data = [(0, 5), (1, 0), (3, 4), (4, 6), (5, -1), (6,1)]\n",
    "e = spark.createDataFrame(data, ['src', 'dst'])\n",
    "v = e.select(col('src').alias('id'), when(e.dst == -1, 0).otherwise(1).alias('d'))\n",
    "v1 = spark.createDataFrame([(-1, 0)], ['id', 'd'])\n",
    "v = v.union(v1)\n",
    "v.show()\n",
    "e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while e.filter('dst != -1').count() > 0:\n",
    "    g = GraphFrame(v, e)\n",
    "    g.cache()\n",
    "    v = g.triplets.select(col('src.id').alias('id'), \n",
    "                          (col('src.d') + col('dst.d')).alias('d')) \\\n",
    "         .union(v1)\n",
    "    e = g.find('(a)-[]->(b); (b)-[]->(c)') \\\n",
    "         .select(col('a.id').alias('src'), col('c.id').alias('dst')) \\\n",
    "         .union(e.filter('dst = -1'))\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/tmp/spark-774f52b2-e773-4dad-97bd-8115b75ace1f/userFiles-1e0f9cb8-6545-428b-bdc6-eb51cbf80d95', '', '/usr/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip', '/usr/spark-2.4.4-bin-hadoop2.7/python', '/home/chris/Downloads/5003', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python27.zip', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7/plat-linux2', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7/lib-tk', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7/lib-old', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7/lib-dynload', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages', '/home/chris/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/IPython/extensions', '/home/chris/.ipython']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "# Example Input:\n",
    "# Vertices DataFrame\n",
    "v = spark.createDataFrame([\n",
    " (\"a\", \"Alice\", 34),\n",
    " (\"b\", \"Bob\", 36),\n",
    " (\"c\", \"Charlie\", 37)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Edges DataFrame\n",
    "e = spark.createDataFrame([\n",
    " (\"a\", \"b\", \"follow\"),\n",
    " (\"c\", \"a\", \"friend\"),\n",
    " (\"b\", \"c\", \"follow\"),\n",
    " (\"d\", \"a\", \"follow\"),\n",
    " (\"f\", \"c\", \"follow\"),\n",
    " (\"f\", \"d\", \"follow\"),\n",
    " (\"f\", \"b\", \"follow\"),\n",
    " (\"c\", \"d\", \"follow\"),\n",
    " (\"g\", \"a\", \"friend\"),\n",
    " (\"g\", \"d\", \"friend\"),\n",
    " (\"g\", \"c\", \"friend\"),\n",
    " (\"e\", \"a\", \"follow\"),\n",
    " (\"e\", \"d\", \"follow\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_get_object_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-2878bfb6b35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#v.join(e,'id').show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#e.filter(\" e.src= 'a' and relationship = 'follow' \").show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/column.pyc\u001b[0m in \u001b[0;36m_\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mnjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         args_command = \"\".join(\n\u001b[0;32m-> 1218\u001b[0;31m             [get_command_part(arg, self.pool) for arg in new_args])\n\u001b[0m\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_command_part\u001b[0;34m(parameter, python_proxy_pool)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mcommand_part\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\";\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mcommand_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mcommand_part\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1301\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_get_object_id'"
     ]
    }
   ],
   "source": [
    "a='a'\n",
    "c=e.filter(e.relationship ==\"follow\")\n",
    "e.filter(c.src==a).select('dst')\n",
    "#v.join(e,'id').show()\n",
    "v.filter(v.id==e)\n",
    "#e.filter(\" e.src= 'a' and relationship = 'follow' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|dst|\n",
      "+---+\n",
      "|  c|\n",
      "|  d|\n",
      "|  b|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e1 = g.edges.filter(\"relationship = 'follow'\")\n",
    "v1 = e1.groupBy('dst').count().select('dst')\n",
    "v2 = e1.groupBy('src').count().orderBy('count', ascending=False)\n",
    "v3 = v2.select('src').subtract(v1.select('dst'))\n",
    "v4 = v3.join(v2,'src').first()\n",
    "e.filter(e['src']==v4.src).select('dst').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  a|  Alice| 34|\n",
      "|  b|    Bob| 36|\n",
      "|  c|Charlie| 37|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  b|      follow|\n",
      "|  a|  c|      follow|\n",
      "|  b|  c|      friend|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.vertices.show()\n",
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|dst|\n",
      "+---+\n",
      "|  c|\n",
      "|  b|\n",
      "+---+\n",
      "\n",
      "+---+-----+\n",
      "|src|count|\n",
      "+---+-----+\n",
      "|  a|    2|\n",
      "+---+-----+\n",
      "\n",
      "+---+\n",
      "|src|\n",
      "+---+\n",
      "|  a|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#g.outDegrees.select(\"id\").where('outDegree=2').show()\n",
    "\n",
    "b=g.edges.filter(\"relationship = 'follow'\")\n",
    "#help(a['id'])\n",
    "a= b.groupBy('dst').count().select('dst')\n",
    "c= b.groupBy('src').count().orderBy('count',ascending=False)\n",
    "d=c.select('src').subtract(a)\n",
    "a.show()\n",
    "c.show()\n",
    "d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=g.outDegrees.groupby().max('outDegree').collect()[0].asDict()['max(outDegree)']\n",
    "\n",
    "b=g.outDegrees.filter(\"outDegree=a\").select(\"id\")\n",
    "#b.show()\n",
    "#g.edges.filter('src=b').show()\n",
    "\n",
    "#g.vertices.join(b,'id','left_outer')..show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "v = spark.createDataFrame([\n",
    " (\"a\", \"Alice\", 34),\n",
    " (\"b\", \"Bob\", 36),\n",
    " (\"c\", \"Charlie\", 37),\n",
    " (\"d\", \"David\", 29),\n",
    " (\"e\", \"Esther\", 32),\n",
    " (\"f\", \"Fanny\", 38),\n",
    " (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Edges DataFrame\n",
    "e = spark.createDataFrame([\n",
    " (\"a\", \"b\", \"follow\"),\n",
    " (\"a\", \"c\", \"friend\"),\n",
    " (\"a\", \"d\", \"friend\"),\n",
    " (\"b\", \"c\", \"friend\"),\n",
    " (\"b\", \"d\", \"friend\"),\n",
    " (\"c\", \"a\", \"friend\"),\n",
    " (\"c\", \"b\", \"friend\"),\n",
    " (\"d\", \"a\", \"friend\"),\n",
    " (\"d\", \"b\", \"friend\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name| name|\n",
      "+----+-----+\n",
      "| Bob|Alice|\n",
      "| Bob|Alice|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find('(a)-[e]->(b);(a)-[h]->(d);(d)-[k]->(b)').filter(\"e.relationship='friend'\").filter(\"h.relationship='friend'\").filter(\"k.relationship='follow'\").select('b.name','d.name').distinct().show()\n",
    "#g.find('(a)-[e]->(b);(b)-[h]->(a)').filter(\"e.relationship='friend'\").filter(\"h.relationship='friend'\").select('a').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|dst|count|\n",
      "+---+-----+\n",
      "|  g|    3|\n",
      "|  d|    1|\n",
      "|  c|    3|\n",
      "|  b|    1|\n",
      "|  a|    2|\n",
      "+---+-----+\n",
      "\n",
      "+---+-----+\n",
      "|src|count|\n",
      "+---+-----+\n",
      "|  g|    3|\n",
      "|  d|    1|\n",
      "|  c|    3|\n",
      "|  b|    1|\n",
      "|  a|    2|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.edges.filter(\"relationship = 'friend'\").groupby('dst').count().show()\n",
    "g.edges.filter(\"relationship = 'friend'\").groupby('src').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
